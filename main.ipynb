{"cells":[{"metadata":{"id":"e1_Y75QXJS6h"},"cell_type":"markdown","source":"### 텐서플로와 다른 라이브러리 불러오기"},{"metadata":{"id":"YzTlj4YdCip_","trusted":true},"cell_type":"code","source":"# GIF를 만들기위해 설치합니다.\n!pip install -q imageio","execution_count":null,"outputs":[]},{"metadata":{"id":"YfIk2es3hJEd","trusted":true},"cell_type":"code","source":"import tensorflow as tf\nimport glob\nimport imageio\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport os\nimport PIL\nfrom tensorflow.keras import layers\nimport time\nimport pandas as pd\nfrom keras.utils.np_utils import to_categorical\nimport random\nimport base64\nfrom IPython.display import HTML\nimport time; import random; import datetime\n\nfrom IPython import display","execution_count":null,"outputs":[]},{"metadata":{"id":"iYn4MdZnKCey"},"cell_type":"markdown","source":"### 데이터셋 로딩 및 준비\n생성자와 감별자를 훈련하기위해 MNIST 데이터셋을 사용할것입니다. 생성자는 손글씨 숫자 데이터를 닮은 숫자들을 생성할 것입니다. "},{"metadata":{"trusted":true},"cell_type":"code","source":"DFtrain = pd.read_csv('../input/computer-vision-learning-contest-dacon/train.csv')\ntest = pd.read_csv('../input/computer-vision-learning-contest-dacon/test.csv')\nsubmission = pd.read_csv('../input/computer-vision-learning-contest-dacon/submission.csv')","execution_count":null,"outputs":[]},{"metadata":{"id":"NFC2ghIdiZYE","trusted":true},"cell_type":"code","source":"X_train = (DFtrain[[str(i) for i in range(784)]] / 255.).values.reshape(-1, 28, 28, 1)\ny_train = to_categorical(DFtrain['digit'].values)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"idx = random.randint(0, 2048)\nimg = DFtrain.loc[idx, '0':].values.reshape(28, 28).astype(int)\ndigit = DFtrain.loc[idx, 'digit']\nletter = DFtrain.loc[idx, 'letter']\n\nplt.title('Index: %i, Digit: %s, Letter: %s'%(idx, digit, letter))\nplt.imshow(img)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"DFtrain[DFtrain.digit == 0]","execution_count":null,"outputs":[]},{"metadata":{"id":"S4PIDhoDLbsZ","trusted":true},"cell_type":"code","source":"BUFFER_SIZE = 60000\nBATCH_SIZE = 32","execution_count":null,"outputs":[]},{"metadata":{"id":"-yKCCQOoJ7cn","trusted":true},"cell_type":"code","source":"# 데이터 배치를 만들고 섞습니다.\ndef CreatDataSet(X_train):\n    train_dataset = tf.data.Dataset.from_tensor_slices(X_train).shuffle(BUFFER_SIZE).batch(BATCH_SIZE)\n    return train_dataset","execution_count":null,"outputs":[]},{"metadata":{"id":"-tEyxE-GMC48"},"cell_type":"markdown","source":"### 생성자\n\n생성자는 시드값 (seed; 랜덤한 잡음)으로부터 이미지를 생성하기 위해, `tf.keras.layers.Conv2DTranspose` (업샘플링) 층을 이용합니다. 처음 `Dense`층은 이 시드값을 인풋으로 받습니다. 그 다음 원하는 사이즈 28x28x1의 이미지가 나오도록 업샘플링을 여러번 합니다. tanh를 사용하는 마지막 층을 제외한 나머지 각 층마다 활성함수로 `tf.keras.layers.LeakyReLU`을 사용하고 있음을 주목합시다."},{"metadata":{"id":"6bpTcDqoLWjY","trusted":true},"cell_type":"code","source":"def make_generator_model():\n    model = tf.keras.Sequential()\n    model.add(layers.Dense(7*7*256, use_bias=False, input_shape=(100,)))\n    model.add(layers.BatchNormalization())\n    model.add(layers.LeakyReLU())\n\n    model.add(layers.Reshape((7, 7, 256)))\n    assert model.output_shape == (None, 7, 7, 256) # 주목: 배치사이즈로 None이 주어집니다.\n\n    model.add(layers.Conv2DTranspose(128, (5, 5), strides=(1, 1), padding='same', use_bias=False))\n    assert model.output_shape == (None, 7, 7, 128)\n    model.add(layers.BatchNormalization())\n    model.add(layers.LeakyReLU())\n\n    model.add(layers.Conv2DTranspose(64, (5, 5), strides=(2, 2), padding='same', use_bias=False))\n    assert model.output_shape == (None, 14, 14, 64)\n    model.add(layers.BatchNormalization())\n    model.add(layers.LeakyReLU())\n\n    model.add(layers.Conv2DTranspose(1, (5, 5), strides=(2, 2), padding='same', use_bias=False, activation='tanh'))\n    assert model.output_shape == (None, 28, 28, 1)\n\n    return model","execution_count":null,"outputs":[]},{"metadata":{"id":"GyWgG09LCSJl"},"cell_type":"markdown","source":"(아직 훈련이 되지않은) 생성자를 이용해 이미지를 생성해봅시다. "},{"metadata":{"id":"gl7jcC7TdPTG","trusted":true},"cell_type":"code","source":"generator = make_generator_model()\n\nnoise = tf.random.normal([1, 100])\ngenerated_image = generator(noise, training=False)\n\nplt.imshow(generated_image[0, :, :, 0], cmap='gray')","execution_count":null,"outputs":[]},{"metadata":{"id":"D0IKnaCtg6WE"},"cell_type":"markdown","source":"### 감별자 \n감별자는 합성곱 신경망(Convolutional Neural Network, CNN) 기반의 이미지 분류기입니다. "},{"metadata":{"id":"dw2tPLmk2pEP","trusted":true},"cell_type":"code","source":"def make_discriminator_model():\n    model = tf.keras.Sequential()\n    model.add(layers.Conv2D(64, (5, 5), strides=(2, 2), padding='same',\n                                     input_shape=[28, 28, 1]))\n    model.add(layers.LeakyReLU())\n    model.add(layers.Dropout(0.3))\n\n    model.add(layers.Conv2D(128, (5, 5), strides=(2, 2), padding='same'))\n    model.add(layers.LeakyReLU())\n    model.add(layers.Dropout(0.3))\n\n    model.add(layers.Flatten())\n    model.add(layers.Dense(1))\n\n    return model","execution_count":null,"outputs":[]},{"metadata":{"id":"QhPneagzCaQv"},"cell_type":"markdown","source":"(아직까지 훈련이 되지 않은) 감별자를 사용하여, 생성된 이미지가 진짜인지 가짜인지 판별합니다. 모델은 진짜 이미지에는 양수의 값 (positive values)을, 가짜 이미지에는 음수의 값 (negative values)을 출력하도록 훈련되어집니다."},{"metadata":{"id":"gDkA05NE6QMs","trusted":true},"cell_type":"code","source":"discriminator = make_discriminator_model()\ndecision = discriminator(generated_image)\nprint (decision)","execution_count":null,"outputs":[]},{"metadata":{"id":"0FMYgY_mPfTi"},"cell_type":"markdown","source":"## 손실함수와 옵티마이저 정의\n두 모델의 손실함수와 옵티마이저를 정의합니다. "},{"metadata":{"id":"psQfmXxYKU3X","trusted":true},"cell_type":"code","source":"# 이 메서드는 크로스 엔트로피 손실함수 (cross entropy loss)를 계산하기 위해 헬퍼 (helper) 함수를 반환합니다.\ncross_entropy = tf.keras.losses.BinaryCrossentropy(from_logits=True)","execution_count":null,"outputs":[]},{"metadata":{"id":"PKY_iPSPNWoj"},"cell_type":"markdown","source":"### 감별자 손실함수\n\n이 메서드는 감별자가 가짜 이미지에서 얼마나 진짜 이미지를 잘 판별하는지 수치화합니다. 진짜 이미지에 대한 감별자의 예측과 1로 이루어진 행렬을 비교하고, 가짜 (생성된) 이미지에 대한 감별자의 예측과 0으로 이루어진 행렬을 비교합니다."},{"metadata":{"id":"wkMNfBWlT-PV","trusted":true},"cell_type":"code","source":"def discriminator_loss(real_output, fake_output):\n    real_loss = cross_entropy(tf.ones_like(real_output), real_output)\n    fake_loss = cross_entropy(tf.zeros_like(fake_output), fake_output)\n    total_loss = real_loss + fake_loss\n    return total_loss","execution_count":null,"outputs":[]},{"metadata":{"id":"Jd-3GCUEiKtv"},"cell_type":"markdown","source":"### 생성자 손실함수\n\n생성자의 손실함수는 감별자를 얼마나 잘 속였는지에 대해 수치화를 합니다. 직관적으로 생성자가 원활히 수행되고 있다면, 감별자는 가짜 이미지를 진짜 (또는 1)로 분류를 할 것입니다. 여기서 우리는 생성된 이미지에 대한 감별자의 결정을 1로 이루어진 행렬과 비교를 할 것입니다. "},{"metadata":{"id":"90BIcCKcDMxz","trusted":true},"cell_type":"code","source":"def generator_loss(fake_output):\n    return cross_entropy(tf.ones_like(fake_output), fake_output)","execution_count":null,"outputs":[]},{"metadata":{"id":"MgIc7i0th_Iu"},"cell_type":"markdown","source":"감별자와 생성자는 따로 훈련되기 때문에, 감별자와 생성자의 옵티마이저는 다릅니다."},{"metadata":{"id":"iWCn_PVdEJZ7","trusted":true},"cell_type":"code","source":"generator_optimizer = tf.keras.optimizers.Adam(1e-4)\ndiscriminator_optimizer = tf.keras.optimizers.Adam(1e-4)","execution_count":null,"outputs":[]},{"metadata":{"id":"mWtinsGDPJlV"},"cell_type":"markdown","source":"### 체크포인트 저장\n이 노트북은 오랫동안 진행되는 훈련이 방해되는 경우에 유용하게 쓰일 수 있는 모델의 저장방법과 복구방법을 보여줍니다. "},{"metadata":{"id":"CA1w-7s2POEy","trusted":true},"cell_type":"code","source":"checkpoint_dir = './training_checkpoints'\ncheckpoint_prefix = os.path.join(checkpoint_dir, \"ckpt\")\ncheckpoint = tf.train.Checkpoint(generator_optimizer=generator_optimizer,\n                                 discriminator_optimizer=discriminator_optimizer,\n                                 generator=generator,\n                                 discriminator=discriminator)","execution_count":null,"outputs":[]},{"metadata":{"id":"Rw1fkAczTQYh"},"cell_type":"markdown","source":"## 훈련 루프 정의하기"},{"metadata":{"id":"NS2GWywBbAWo","trusted":true},"cell_type":"code","source":"EPOCHS = 4000\nnoise_dim = 100\nnum_examples_to_generate = 16\n\n# 이 시드를 시간이 지나도 재활용하겠습니다. \n# (GIF 애니메이션에서 진전 내용을 시각화하는데 쉽기 때문입니다.) \nseed = tf.random.normal([num_examples_to_generate, noise_dim])","execution_count":null,"outputs":[]},{"metadata":{"id":"jylSonrqSWfi"},"cell_type":"markdown","source":"훈련 루프는 생성자가 입력으로 랜덤시드를 받는 것으로부터 시작됩니다. 그 시드값을 사용하여 이미지를 생성합니다. 감별자를 사용하여 (훈련 세트에서 갖고온) 진짜 이미지와 (생성자가 생성해낸) 가짜이미지를 분류합니다. 각 모델의 손실을 계산하고, 그래디언트 (gradients)를 사용해 생성자와 감별자를 업데이트합니다."},{"metadata":{"id":"3t5ibNo05jCB","trusted":true},"cell_type":"code","source":"# `tf.function`이 어떻게 사용되는지 주목해 주세요.\n# 이 데코레이터는 함수를 \"컴파일\"합니다.\n@tf.function\ndef train_step(images):\n    noise = tf.random.normal([BATCH_SIZE, noise_dim])\n\n    with tf.GradientTape() as gen_tape, tf.GradientTape() as disc_tape:\n      generated_images = generator(noise, training=True)\n\n      real_output = discriminator(images, training=True)\n      fake_output = discriminator(generated_images, training=True)\n\n      gen_loss = generator_loss(fake_output)\n      disc_loss = discriminator_loss(real_output, fake_output)\n\n    gradients_of_generator = gen_tape.gradient(gen_loss, generator.trainable_variables)\n    gradients_of_discriminator = disc_tape.gradient(disc_loss, discriminator.trainable_variables)\n\n    generator_optimizer.apply_gradients(zip(gradients_of_generator, generator.trainable_variables))\n    discriminator_optimizer.apply_gradients(zip(gradients_of_discriminator, discriminator.trainable_variables))","execution_count":null,"outputs":[]},{"metadata":{"id":"2M7LmLtGEMQJ","trusted":true},"cell_type":"code","source":"def train(dataset, epochs, numValue):\n  for epoch in range(epochs):\n    start = time.time()\n\n    for image_batch in dataset:\n      train_step(image_batch)\n\n    # GIF를 위한 이미지를 바로 생성합니다.\n    if epoch % 100 == 0:\n        display.clear_output(wait=True)\n        generate_and_save_images(generator,\n                                 epoch + 1,\n                                 seed,\n                                 numValue)\n\n    # 15 에포크가 지날 때마다 모델을 저장합니다.\n    if (epoch + 1) % 15 == 0:\n      checkpoint.save(file_prefix = checkpoint_prefix)\n    \n    # print (' 에포크 {} 에서 걸린 시간은 {} 초 입니다'.format(epoch +1, time.time()-start))\n    print ('Num {} time for epoch {} is {} sec'.format(numValue, epoch + 1, time.time()-start))\n\n  # 마지막 에포크가 끝난 후 생성합니다.\n  display.clear_output(wait=True)\n  generate_and_save_images(generator,\n                           epochs,\n                           seed,\n                           numValue)","execution_count":null,"outputs":[]},{"metadata":{"id":"2aFF7Hk3XdeW"},"cell_type":"markdown","source":"**이미지 생성 및 저장**\n"},{"metadata":{"id":"RmdVsmvhPxyy","trusted":true},"cell_type":"code","source":"def generate_and_save_images(model, epoch, test_input, k):\n  # `training`이 False로 맞춰진 것을 주목하세요.\n  # 이렇게 하면 (배치정규화를 포함하여) 모든 층들이 추론 모드로 실행됩니다. \n  predictions = model(test_input, training=False)\n\n  fig = plt.figure(figsize=(4,4))\n\n  for i in range(predictions.shape[0]):\n      plt.subplot(4, 4, i+1)\n      plt.imshow(predictions[i, :, :, 0] * 127.5 + 127.5, cmap='gray')\n      plt.axis('off')\n\n  plt.savefig('NUM{}_image_at_epoch_{:04d}.png'.format(k, epoch))\n  plt.show()","execution_count":null,"outputs":[]},{"metadata":{"id":"dZrd4CdjR-Fp"},"cell_type":"markdown","source":"## 모델 훈련\n위에 정의된 `train()` 메서드를 생성자와 감별자를 동시에 훈련하기 위해 호출합니다. 생성적 적대 신경망을 학습하는 것은 매우 까다로울 수 있습니다. 생성자와 감별자가 서로를 제압하지 않는 것이 중요합니다. (예를 들어 학습률이 비슷하면 한쪽이 우세해집니다.)\n훈련 초반부에는 생성된 이미지는 랜덤한 노이즈처럼 보입니다. 훈련이 진행될수록, 생성된 숫자는 점차 진짜처럼 보일 것입니다. 약 50 에포크가 지난 후, MNIST 숫자와 닮은 이미지가 생성됩니다. 코랩에서 기본 설정으로 실행하면, 에포크마다 1분정도 소요될 것입니다."},{"metadata":{"id":"Ly3UN0SLLY2l","trusted":true},"cell_type":"code","source":"weight_dir = './weight/'\nweight_prefix = os.path.join(checkpoint_dir, \"ckpt\")\n\nfor i in range(0, 10):\n#     %%time\n    train(CreatDataSet(np.array(DFtrain[DFtrain.digit == i].drop(['id', 'digit', 'letter'], axis=1, inplace=False)).reshape(-1, 28, 28, 1)), EPOCHS, i)\n\n#     discriminator.save(f'./weight/NUM-{i}-Params.h5')\n    \n    discriminator.save(f'NUM-{i}-Params.h5')\n    \n    model_json = discriminator.to_json()\n    with open(f\"NUM{i}.json\", \"w\") as json_file : \n        json_file.write(model_json)","execution_count":null,"outputs":[]},{"metadata":{"id":"rfM4YcPVPkNO"},"cell_type":"markdown","source":"마지막 체크포인트를 복구합니다."},{"metadata":{"id":"XhXsd0srPo8c","trusted":true},"cell_type":"code","source":"checkpoint.restore(tf.train.latest_checkpoint(checkpoint_dir))","execution_count":null,"outputs":[]},{"metadata":{"id":"P4M_vIbUi7c0"},"cell_type":"markdown","source":"## GIF 생성"},{"metadata":{"id":"WfO5wCdclHGL","trusted":true},"cell_type":"code","source":"# 에포크 숫자를 사용하여 하나의 이미지를 보여줍니다.\ndef display_image(epoch_no, num):\n  return PIL.Image.open('NUM{}_image_at_epoch_{:04d}.png'.format(num, epoch_no))","execution_count":null,"outputs":[]},{"metadata":{"id":"5x3q9_Oe5q0A","trusted":true},"cell_type":"code","source":"for i in range (0, 10):\n    display_image(EPOCHS, i)","execution_count":null,"outputs":[]},{"metadata":{"id":"NywiH3nL8guF"},"cell_type":"markdown","source":"`imageio`로 훈련 중에 저장된 이미지를 사용해 GIF 애니메이션을 만듭니다."},{"metadata":{"id":"IGKQgENQ8lEI","trusted":true},"cell_type":"code","source":"anim_file = 'dcgan.gif'\n\nfor i in range(0, 10):\n    with imageio.get_writer(f'NUM-{i}-dcgan.gif', mode='I') as writer:\n      filenames = glob.glob('NUM{}_image_at_epoch_{:04d}.png'.format(i, i))\n      filenames = sorted(filenames)\n      last = -1\n      for i,filename in enumerate(filenames):\n        frame = 2*(i**0.5)\n        if round(frame) > round(last):\n          last = frame\n        else:\n          continue\n        image = imageio.imread(filename)\n        writer.append_data(image)\n        image = imageio.imread(filename)\n        writer.append_data(image)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import IPython\n# for i in range(0, 10):\ndisplay.Image(filename=f'NUM-{1}-dcgan.gif')","execution_count":null,"outputs":[]},{"metadata":{"id":"cGhC3-fMWSwl"},"cell_type":"markdown","source":"코랩에서 작업하고 있다면, 아래의 코드에서 애니메이션을 다운로드 받을 수 있습니다: "},{"metadata":{"trusted":true},"cell_type":"code","source":"now = datetime.datetime.now().strftime('%Y-%m-%d %H_%M_%S')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# make_discriminator_model(img)\n\ndiscriminator = make_discriminator_model()\ndecision = discriminator(img.reshape(1, 28, 28, 1))\nprint(decision)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"Ans = []\nfor i in range(0, 10):\n    new_model = tf.keras.models.load_model(f'./NUM-{i}-Params.h5')\n    \n    decision = new_model(img.reshape(1, 28, 28, 1))\n    Ans.append(decision)\n    \n\ntf.nn.softmax(np.array(Ans).reshape(10), axis=None, name=None)\n# np.array(Ans).reshape(10,)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Todo\n\n1. 숫자별 DCGAN 만들기\n2. 숫자별 예측하기\n3. 기존 CNN 모델과 앙상블 하기\n4. Random한 곳들에 seed 넣기\n5. 감별자 model 바꾸기"}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":4}